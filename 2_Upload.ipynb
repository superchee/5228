{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "# functions needed for pr_auc_score()\n",
    "from sklearn.metrics import auc, precision_recall_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "# functions needed for imbalanced_cross_validation_score()\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# sampler objects\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler, NeighbourhoodCleaningRule, AllKNN, InstanceHardnessThreshold\n",
    "\n",
    "# Classification models to compare\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB # naive bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.svm import SVC # SVM\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, BalancedRandomForestClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn import preprocessing \n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_auc_score(clf, x, y):\n",
    "    '''\n",
    "        This function computes area under the precision-recall curve. \n",
    "    '''\n",
    "      \n",
    "    precisions, recalls,_ = precision_recall_curve(y, clf.predict_proba(x)[:,1], pos_label=1)\n",
    "    \n",
    "    return auc(recalls, precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Confusion_matrix(clf, x, y):\n",
    "    cm = metrics.confusion_matrix(y, clf.predict(x))\n",
    "    mcc = matthews_corrcoef(y, clf.predict(x))\n",
    "    \n",
    "    return (cm[0][0], cm[0][1], cm[1][0], cm[1][1], mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imbalanced_cross_validation_score(clf, x, y, cv, scoring, sampler):\n",
    "    \n",
    "    cv_score = 0.\n",
    "    train_score = 0.\n",
    "    test_score = 0.\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    MCC = 0\n",
    "    \n",
    "    # stratified k-fold creates folds with the same ratio of positive \n",
    "    # and negative samples as the entire dataset.\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=cv, random_state=0, shuffle=False)\n",
    "    \n",
    "    for train_idx, test_idx in skf.split(x,y):\n",
    "        \n",
    "        xfold_train_sampled, yfold_train_sampled = sampler.fit_sample(x[train_idx],y[train_idx])\n",
    "        clf.fit(xfold_train_sampled, yfold_train_sampled)\n",
    "        \n",
    "        TN_train, FP_train, FN_train, TP_train, mcc_train = scoring(clf, xfold_train_sampled, yfold_train_sampled)\n",
    "        TN_test, FP_test, FN_test, TP_test, mcc_test  = scoring(clf, x[test_idx], y[test_idx])\n",
    "        # tn, fp, fn, tp\n",
    "        print(\"Train TP: {0} Train FP: {1} Train FN: {2} Train TN: {3}; Test TP: {4} Test FP: {5} Test FN: {6} Test TN: {7}\".format(TP_train, FP_train, FN_train, TN_train, TP_test, FP_test, FN_test, TN_test))\n",
    "        print(\"MCC train: {0} and MCC test: {1}\".format(mcc_train, mcc_test))\n",
    "        \n",
    "        TP += TP_test\n",
    "        FP += FP_test\n",
    "        FN += FN_test\n",
    "        TN += TN_test\n",
    "        MCC += mcc_test\n",
    "\n",
    "    ave_tp = TP/cv\n",
    "    ave_fp = FP/cv\n",
    "    ave_fn = FN/cv\n",
    "    ave_tn = TN/cv\n",
    "    ave_mcc = MCC/cv\n",
    "    \n",
    "    sensitivity = ave_tp/(ave_tp + ave_fn)\n",
    "    specificity = ave_tn/(ave_fp + ave_tn)\n",
    "    \n",
    "    g_mean = math.sqrt(sensitivity * specificity)\n",
    "    \n",
    "    values = [sensitivity, specificity, g_mean, ave_mcc]\n",
    "    \n",
    "        \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_o = pd.read_csv('financial_data.csv')\n",
    "y_train_o = pd.read_csv('revealed_businesses.csv')\n",
    "\n",
    "x_test_o = pd.read_csv(\"testing_data.csv\")\n",
    "\n",
    "x_train_o.replace('?', np.nan, inplace=True)\n",
    "x_train_o = x_train_o.astype('float64')\n",
    "\n",
    "\n",
    "x_test_o.replace('?', np.nan, inplace=True)\n",
    "x_test_o = x_test_o.astype('float64')\n",
    "\n",
    "data_all = x_train_o.merge(y_train_o, on='Var1', how = 'left')\n",
    "\n",
    "data_nolabel = data_all[data_all.Var66.isnull()]\n",
    "data_label = data_all[data_all.Var66.notnull()]\n",
    "\n",
    "data_nolabel_v = data_nolabel.drop(columns=['Var1', 'Var66'])\n",
    "data_nolabel_id = data_nolabel['Var1']\n",
    "\n",
    "data_label_v = data_label.drop(columns=['Var1', 'Var66'])\n",
    "data_label_id = data_label['Var1']\n",
    "\n",
    "x_test_v = x_test_o.drop(columns=['Var1'])\n",
    "\n",
    "# data_all_v = data_all.drop(columns=['Var1', 'Var66'])\n",
    "# data_all_v_mean = data_all_v.mean()\n",
    "# data_all_v_f = data_all_v.fillna(data_all_v_mean)\n",
    "# minmax_scaler = preprocessing.MinMaxScaler().fit(data_all_v)\n",
    "\n",
    "# data_nolabel_v_f = data_nolabel_v.fillna(data_all_v_mean)\n",
    "# data_label_v_f = data_label_v.fillna(data_all_v_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selected = ['Var23', 'Var26', 'Var28', 'Var30', 'Var47', 'Var19', 'Var35', 'Var57', 'Var10', 'Var12', 'Var45', 'Var33', 'Var16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = pd.concat([data_label_v, x_test_v], axis=0)\n",
    "\n",
    "x_all_s = x_all#[feature_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all_f = x_all_s.fillna(x_all_s.mean()).values\n",
    "x_all_f_scale = x_all_f#preprocessing.RobustScaler().fit_transform(x_all_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_all_f[:4879,:]\n",
    "y = data_label['Var66'].values\n",
    "\n",
    "x_test_scale = x_all_f[4879:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = RandomOverSampler(random_state=42).fit_sample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(learning_rate=0.2,scale_pos_weight=0.5, max_depth=5, subsample=0.7, n_estimators=500, base_score=0.5, gamma=0, colsample_bytree=0.9)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred_dt = clf.predict(x_test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1417\n",
       "1.0      83\n",
       "Name: Is_Bankrupted, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_business_id = x_test_o['Var1']\n",
    "df_y = pd.DataFrame(y_pred_dt, columns=[\"Is_Bankrupted\"])\n",
    "upload = pd.concat([x_test_business_id, df_y], axis=1)\n",
    "df_y[\"Is_Bankrupted\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1417\n",
       "1.0      83\n",
       "Name: Is_Bankrupted, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload['Is_Bankrupted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload = upload.astype('int32')\n",
    "# upload.columns=['Business_ID', 'Is_Bankrupted']\n",
    "# upload.to_csv('4_7_roc_78.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
